{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "import copy\n",
    "import requests\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    # # check Z score\n",
    "    # zscore = pd.DataFrame()\n",
    "    # outlier = {}\n",
    "    # outlier_idx = []\n",
    "    # for col in data_scaled.columns:\n",
    "    #     if col != data_scaled.columns[0]:\n",
    "    #         zscore[f'{col}_z'] = sp.stats.zscore(data_scaled[col])\n",
    "    #         outlier[col] = zscore[f'{col}_z'][(zscore[f'{col}_z']>2.58) | (zscore[f'{col}_z']<-2.58)] # 99% = 2.58\n",
    "    #         outlier_idx.append(list(outlier[col].index))    \n",
    "    # outlier_idx_sum = sum(outlier_idx,[])\n",
    "    # data_scaled = data_scaled.drop(outlier_idx_sum)\n",
    "\n",
    "    # IQR outlier + mean으로 대체 \n",
    "    class_label = data['Class Label'].copy()\n",
    "    data_pre = data.loc[:, data.columns != 'Class Label'].copy()\n",
    "    for col in data_pre.columns:\n",
    "        q1 = np.quantile(data_pre[f'{col}'], 0.25)\n",
    "        q3 = np.quantile(data_pre[f'{col}'], 0.75)\n",
    "        IQR = q3 - q1\n",
    "        condition = (data_pre[f'{col}'] < (q1 - 1.5 * IQR)) | (data_pre[f'{col}'] > (q3 + 1.5 * IQR))\n",
    "        outlier = data_pre[condition]\n",
    "        data_pre[f'{col}'] = data_pre[f'{col}'].replace([data_pre[f'{col}'][outlier.index]], data_pre[f'{col}'].mean())            \n",
    "    \n",
    "    # regularization 표준화\n",
    "    # regularization = StandardScaler()\n",
    "    # regularization.fit(data_pre)\n",
    "    # data_scaled = regularization.transform(data_pre)\n",
    "    # data_scaled = pd.DataFrame(data=data_scaled, columns=data_pre.columns)\n",
    "    # data_scaled[data_scaled.columns[0]] = label\n",
    "\n",
    "    sLink = 'https://github.com/2U1/ML_RDACOV/blob/master/scaler.pkl?raw=True'\n",
    "    sFile = BytesIO(requests.get(sLink).content)\n",
    "    scaler = pickle.load(sFile)\n",
    "    data_scaled = scaler.transform(data_pre)\n",
    "    data_scaled = pd.DataFrame(data=data_scaled, columns=data_pre.columns)\n",
    "\n",
    "    # # Normalization\n",
    "    # normalization = MinMaxScaler()\n",
    "    # normalization.fit(data_pre)\n",
    "    # data_nor = normalization.transform(data_pre)\n",
    "    # data_nor = pd.DataFrame(data=data_nor, columns=data_pre.columns)\n",
    "    # data_nor[data_nor.columns[0]] = data_pre[data_pre.columns[0]]\n",
    "    # data_nor[data_nor.columns[0]] = label\n",
    "    \n",
    "\n",
    "    data_processed = pd.concat([class_label, data_scaled], axis=1)\n",
    "\n",
    "    return data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred, average='macro')\n",
    "    precision = precision_score(y_test, pred, average='macro')\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "    print('Accuracy:{0:.4f}, Recall:{1:.4f}, Precision:{2:.4f}, F1-Score:{3:.4f}'.format(accuracy, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    confusion_df = pd.DataFrame(confusion,columns=['Predicted_1','Predicted_2', 'Predicted_3'],index=['Predicted_1','Predicted_2', 'Predicted_3'])\n",
    "    \n",
    "    return confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory, preprocess = False, data_split = False):\n",
    "    \n",
    "    global input_cnt, output_cnt, data, x, y\n",
    "\n",
    "    data = pd.read_csv(directory)\n",
    "    \n",
    "    if preprocess:\n",
    "        data = data_preprocessing(data)\n",
    "\n",
    "    input_cnt = data.loc[:, data.columns != 'Class Label'].shape[1]\n",
    "    # output_cnt = data['Class Label'].shape[1]\n",
    "    output_cnt = 1\n",
    "    y = data['Class Label'].to_numpy()\n",
    "    x = data.loc[:, data.columns != 'Class Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminentAnalysis():\n",
    "    def __init__(self, alpha=0.0, beta=0.0, eval_mode = False):\n",
    "        if not eval_mode:\n",
    "            self.learned = False\n",
    "            self.alpha = alpha\n",
    "            self.beta = beta\n",
    "            self.class_names = []\n",
    "            self.class_priors = {}\n",
    "            self.class_means = {}\n",
    "            self.regularized_covariances = {}\n",
    "            self.rda_covariances = {}\n",
    "            self.reset()\n",
    "\n",
    "        else:\n",
    "            self.load_parameter()\n",
    "\n",
    "\n",
    "    def load_parameter(self):\n",
    "        mLink = 'https://github.com/2U1/ML_RDACOV/blob/master/parameter.pkl?raw=true'\n",
    "        mfile = BytesIO(requests.get(mLink).content)\n",
    "        parameter = pickle.load(mfile)\n",
    "        \n",
    "\n",
    "        self.learned = True\n",
    "        self.alpha = parameter['alpha']\n",
    "        self.beta = parameter['beta']\n",
    "        self.class_names = parameter['class_name']\n",
    "        self.class_priors = parameter['calss_priors']\n",
    "        self.class_means = parameter['class_means']\n",
    "        self.regularized_covariances = parameter['reg_cov']\n",
    "        self.rda_covariances = parameter['rda_cov']\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.learned = False\n",
    "        self.class_names = []\n",
    "        self.class_priors = {}\n",
    "        self.class_means = {}\n",
    "        self.regularized_covariances = {}\n",
    "        self.rda_covariances = {}\n",
    "\n",
    "\n",
    "    def return_parameters(self):\n",
    "        parameters = {\n",
    "            'alpha': self.alpha,\n",
    "            'beta': self.beta,\n",
    "            'class_name': self.class_names,\n",
    "            'class_priors': self.class_priors,\n",
    "            'class_means': self.class_means,\n",
    "            'reg_cov': self.regularized_covariances,\n",
    "            'rda_cov': self.rda_covariances\n",
    "        }\n",
    "\n",
    "        return parameters\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_names = np.unique(y)\n",
    "        class_covariances = {}\n",
    "        pooled_covariances = 0\n",
    "        for i in self.class_names:\n",
    "            class_indices = np.where(y == i)[0]\n",
    "            class_samples = X[class_indices, :]\n",
    "            self.class_priors[i] = float(len(class_indices)) / len(y)\n",
    "            self.class_means[i] = np.mean(class_samples, axis=0)\n",
    "            class_covariances[i] = np.cov(class_samples, rowvar=0)\n",
    "            pooled_covariances += class_covariances[i] * self.class_priors[i]\n",
    "        # Calculate RDA regularized covariance matricies for each class\n",
    "        for i in self.class_names:\n",
    "            self.regularized_covariances[i] = (self.beta * pooled_covariances) + ((1 - self.beta) *class_covariances[i])\n",
    "            # self.regularized_covariances[i] = (self.beta * class_covariances[i]) + ((1 - self.beta) * pooled_covariances)\n",
    "\n",
    "        for i in self.class_names:\n",
    "            self.rda_covariances[i] = ((1-self.alpha) * self.regularized_covariances[i]) + (self.alpha * (1/self.class_priors[i]) * np.trace(self.regularized_covariances[i]) * np.eye(self.regularized_covariances[i].shape[0]))\n",
    "        \n",
    "        self.learned = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        if not self.learned:\n",
    "            raise NameError('Fit model first')\n",
    "        # Determine probability of each class given input vector\n",
    "        \n",
    "        class_prob = {}\n",
    "        for i in self.class_names:\n",
    "            # Divid the class delta calculation into 3 parts\n",
    "            part1 = -0.5 * np.log1p(np.linalg.det(self.rda_covariances[i]))\n",
    "            # part2 = -0.5 * np.dot(np.dot((x - self.class_means[i]).T, np.linalg.pinv(self.rda_covariances[i])), (x - self.class_means[i]))\n",
    "            part2 = -0.5 * np.matmul(np.matmul((x - self.class_means[i]).T, np.linalg.pinv(self.rda_covariances[i])), (x - self.class_means[i]))\n",
    "            part3 = np.log(self.class_priors[i])\n",
    "            class_prob[i] = part1 + part2 + part3\n",
    "        return max(class_prob, key=class_prob.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchRDA():\n",
    "    def __init__(self, model, param_grid):\n",
    "        self.model = model\n",
    "        self.param_grid = param_grid\n",
    "        self.alpha = 0\n",
    "        self.beta = 0\n",
    "        self.best_covariance = {}\n",
    "        self.best_score = 0\n",
    "\n",
    "\n",
    "    def fit(self, X, y, cv=2):\n",
    "        \n",
    "        # metric_score = []\n",
    "\n",
    "        data_length = len(X)\n",
    "        \n",
    "        alpha_list = self.param_grid['alpha']\n",
    "        beta_list = self.param_grid['beta']\n",
    "        \n",
    "        if data_length % cv == 0:\n",
    "            cv_x = np.split(X, cv)\n",
    "            cv_y = np.split(y, cv)\n",
    "            \n",
    "        else:\n",
    "            remain = data_length % cv\n",
    "            cv_x = np.split(X[:-remain], cv)\n",
    "            cv_y = np.split(y[:-remain], cv)\n",
    "\n",
    "        for alpha in alpha_list:\n",
    "            for beta in beta_list:\n",
    "                accuracy_score_list = []\n",
    "                recall_score_list = []\n",
    "                precision_score_list = []\n",
    "                f1_score_list = []\n",
    "                for i in range(cv):\n",
    "                    self.model.reset()\n",
    "                    self.model.alpha = alpha\n",
    "                    self.model.beta = beta\n",
    "\n",
    "                    test_x_cv = cv_x[i]\n",
    "                    train_x_cv = np.vstack(cv_x[:i] + cv_x[i + 1:])\n",
    "\n",
    "                    test_y_cv = cv_y[i]\n",
    "                    train_y_cv = np.vstack(cv_y[:i] + cv_y[i + 1:]).flatten()\n",
    "\n",
    "                    \n",
    "                    self.model.fit(train_x_cv, train_y_cv)\n",
    "\n",
    "                    pred = []\n",
    "\n",
    "                    for data in test_x_cv:\n",
    "                        pred.append(self.model.predict(data))\n",
    "                    \n",
    "                    accuracy_score_list.append(accuracy_score(test_y_cv, pred))\n",
    "                    recall_score_list.append(recall_score(test_y_cv, pred, average='macro'))\n",
    "                    precision_score_list.append(precision_score(test_y_cv, pred, average='macro'))\n",
    "                    f1_score_list.append(f1_score(test_y_cv, pred, average='macro'))\n",
    "                \n",
    "                accuracy_mean_score = np.mean(np.array(accuracy_score_list))\n",
    "                recall_mean_score = np.mean(np.array(recall_score_list))\n",
    "                precision_mean_score = np.mean(np.array(precision_score_list))\n",
    "                f1_mean_score = np.mean(np.array(f1_score_list))\n",
    "\n",
    "                print(\"alpha:{0:.1f}, beta:{1:.1f}, accuracy:{2:.4f}, recall:{3:.4f}, precision:{4:.4f} ,f1-score:{5:.4f}\"\\\n",
    "                    .format(alpha, beta, accuracy_mean_score ,recall_mean_score ,precision_mean_score ,f1_mean_score))\n",
    "\n",
    "                if f1_mean_score > self.best_score:\n",
    "                    self.best_score = f1_mean_score\n",
    "                    self.alpha = alpha\n",
    "                    self.beta = beta\n",
    "                    self.best_covariance = copy.deepcopy(self.model.rda_covariances)\n",
    "                    self.best_estimator = copy.deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(test_x, test_y):\n",
    "\n",
    "    model = DiscriminentAnalysis(eval_mode=True)\n",
    "\n",
    "\n",
    "    prediction = []\n",
    "    \n",
    "    for testing in test_x:\n",
    "        prediction.append(model.predict(testing))\n",
    "\n",
    "\n",
    "    confusion = make_confusion(test_y, prediction)\n",
    "    \n",
    "    get_clf_eval(test_y, prediction)\n",
    "    print('\\n\\n')\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset('./facial_expression_train_dataset.csv', preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = DiscriminentAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': np.linspace(0.0, 1.0, num=11, endpoint=True),\n",
    "    'beta': np.linspace(0.0, 1.0, num=11, endpoint=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchRDA(dis, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnm\\Anaconda3\\envs\\DL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:0.0, beta:0.0, accuracy:0.8923, recall:0.8556, precision:0.8651 ,f1-score:0.8373\n",
      "alpha:0.0, beta:0.1, accuracy:0.9692, recall:0.9667, precision:0.9778 ,f1-score:0.9644\n",
      "alpha:0.0, beta:0.2, accuracy:0.9846, recall:0.9833, precision:0.9867 ,f1-score:0.9831\n",
      "alpha:0.0, beta:0.3, accuracy:0.9692, recall:0.9738, precision:0.9700 ,f1-score:0.9684\n",
      "alpha:0.0, beta:0.4, accuracy:0.9692, recall:0.9738, precision:0.9700 ,f1-score:0.9684\n",
      "alpha:0.0, beta:0.5, accuracy:0.9846, recall:0.9905, precision:0.9833 ,f1-score:0.9853\n",
      "alpha:0.0, beta:0.6, accuracy:0.9846, recall:0.9905, precision:0.9833 ,f1-score:0.9853\n",
      "alpha:0.0, beta:0.7, accuracy:0.9846, recall:0.9905, precision:0.9833 ,f1-score:0.9853\n",
      "alpha:0.0, beta:0.8, accuracy:0.9846, recall:0.9905, precision:0.9833 ,f1-score:0.9853\n",
      "alpha:0.0, beta:0.9, accuracy:0.9846, recall:0.9905, precision:0.9833 ,f1-score:0.9853\n",
      "alpha:0.0, beta:1.0, accuracy:0.9846, recall:0.9905, precision:0.9833 ,f1-score:0.9853\n",
      "alpha:0.1, beta:0.0, accuracy:0.6308, recall:0.6554, precision:0.7031 ,f1-score:0.6041\n",
      "alpha:0.1, beta:0.1, accuracy:0.6000, recall:0.6325, precision:0.6689 ,f1-score:0.5684\n",
      "alpha:0.1, beta:0.2, accuracy:0.5385, recall:0.5944, precision:0.6630 ,f1-score:0.5221\n",
      "alpha:0.1, beta:0.3, accuracy:0.5077, recall:0.5754, precision:0.5856 ,f1-score:0.4891\n",
      "alpha:0.1, beta:0.4, accuracy:0.5231, recall:0.5887, precision:0.5939 ,f1-score:0.5060\n",
      "alpha:0.1, beta:0.5, accuracy:0.5385, recall:0.6021, precision:0.6065 ,f1-score:0.5206\n",
      "alpha:0.1, beta:0.6, accuracy:0.6154, recall:0.6810, precision:0.6500 ,f1-score:0.6060\n",
      "alpha:0.1, beta:0.7, accuracy:0.6923, recall:0.7649, precision:0.7082 ,f1-score:0.6932\n",
      "alpha:0.1, beta:0.8, accuracy:0.6923, recall:0.7649, precision:0.7082 ,f1-score:0.6932\n",
      "alpha:0.1, beta:0.9, accuracy:0.7538, recall:0.8271, precision:0.7233 ,f1-score:0.7446\n",
      "alpha:0.1, beta:1.0, accuracy:0.7692, recall:0.8438, precision:0.7422 ,f1-score:0.7626\n",
      "alpha:0.2, beta:0.0, accuracy:0.4000, recall:0.4444, precision:0.2228 ,f1-score:0.2839\n",
      "alpha:0.2, beta:0.1, accuracy:0.3538, recall:0.4159, precision:0.1970 ,f1-score:0.2461\n",
      "alpha:0.2, beta:0.2, accuracy:0.2923, recall:0.3778, precision:0.1332 ,f1-score:0.1897\n",
      "alpha:0.2, beta:0.3, accuracy:0.2923, recall:0.3778, precision:0.1293 ,f1-score:0.1880\n",
      "alpha:0.2, beta:0.4, accuracy:0.3077, recall:0.3911, precision:0.1947 ,f1-score:0.2086\n",
      "alpha:0.2, beta:0.5, accuracy:0.3077, recall:0.3911, precision:0.1971 ,f1-score:0.2111\n",
      "alpha:0.2, beta:0.6, accuracy:0.3385, recall:0.4229, precision:0.3376 ,f1-score:0.2663\n",
      "alpha:0.2, beta:0.7, accuracy:0.4308, recall:0.5151, precision:0.5705 ,f1-score:0.4089\n",
      "alpha:0.2, beta:0.8, accuracy:0.5846, recall:0.6670, precision:0.6303 ,f1-score:0.5847\n",
      "alpha:0.2, beta:0.9, accuracy:0.6923, recall:0.7687, precision:0.6867 ,f1-score:0.6890\n",
      "alpha:0.2, beta:1.0, accuracy:0.7385, recall:0.8083, precision:0.7044 ,f1-score:0.7224\n",
      "alpha:0.3, beta:0.0, accuracy:0.3846, recall:0.4222, precision:0.2051 ,f1-score:0.2601\n",
      "alpha:0.3, beta:0.1, accuracy:0.3077, recall:0.3746, precision:0.1677 ,f1-score:0.2021\n",
      "alpha:0.3, beta:0.2, accuracy:0.2923, recall:0.3778, precision:0.1312 ,f1-score:0.1875\n",
      "alpha:0.3, beta:0.3, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.3, beta:0.4, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.3, beta:0.5, accuracy:0.2923, recall:0.3778, precision:0.1272 ,f1-score:0.1851\n",
      "alpha:0.3, beta:0.6, accuracy:0.2923, recall:0.3778, precision:0.1272 ,f1-score:0.1851\n",
      "alpha:0.3, beta:0.7, accuracy:0.3231, recall:0.4133, precision:0.2642 ,f1-score:0.2448\n",
      "alpha:0.3, beta:0.8, accuracy:0.4615, recall:0.5595, precision:0.5788 ,f1-score:0.4491\n",
      "alpha:0.3, beta:0.9, accuracy:0.6154, recall:0.6970, precision:0.6570 ,f1-score:0.6144\n",
      "alpha:0.3, beta:1.0, accuracy:0.6154, recall:0.7054, precision:0.6033 ,f1-score:0.5905\n",
      "alpha:0.4, beta:0.0, accuracy:0.3692, recall:0.4000, precision:0.2103 ,f1-score:0.2476\n",
      "alpha:0.4, beta:0.1, accuracy:0.2923, recall:0.3651, precision:0.1519 ,f1-score:0.1845\n",
      "alpha:0.4, beta:0.2, accuracy:0.2769, recall:0.3556, precision:0.1157 ,f1-score:0.1661\n",
      "alpha:0.4, beta:0.3, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.4, beta:0.4, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.4, beta:0.5, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.4, beta:0.6, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.4, beta:0.7, accuracy:0.2923, recall:0.3778, precision:0.1272 ,f1-score:0.1851\n",
      "alpha:0.4, beta:0.8, accuracy:0.3538, recall:0.4578, precision:0.3356 ,f1-score:0.3028\n",
      "alpha:0.4, beta:0.9, accuracy:0.5692, recall:0.6684, precision:0.6420 ,f1-score:0.5690\n",
      "alpha:0.4, beta:1.0, accuracy:0.6000, recall:0.6921, precision:0.5209 ,f1-score:0.5596\n",
      "alpha:0.5, beta:0.0, accuracy:0.3692, recall:0.4000, precision:0.2094 ,f1-score:0.2463\n",
      "alpha:0.5, beta:0.1, accuracy:0.2769, recall:0.3556, precision:0.1170 ,f1-score:0.1678\n",
      "alpha:0.5, beta:0.2, accuracy:0.2769, recall:0.3556, precision:0.1157 ,f1-score:0.1661\n",
      "alpha:0.5, beta:0.3, accuracy:0.2769, recall:0.3556, precision:0.1157 ,f1-score:0.1661\n",
      "alpha:0.5, beta:0.4, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.5, beta:0.5, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.5, beta:0.6, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.5, beta:0.7, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.5, beta:0.8, accuracy:0.3538, recall:0.4578, precision:0.3331 ,f1-score:0.3003\n",
      "alpha:0.5, beta:0.9, accuracy:0.5077, recall:0.6156, precision:0.5231 ,f1-score:0.5010\n",
      "alpha:0.5, beta:1.0, accuracy:0.5692, recall:0.6565, precision:0.4992 ,f1-score:0.5304\n",
      "alpha:0.6, beta:0.0, accuracy:0.3692, recall:0.4000, precision:0.2077 ,f1-score:0.2444\n",
      "alpha:0.6, beta:0.1, accuracy:0.2769, recall:0.3556, precision:0.1153 ,f1-score:0.1658\n",
      "alpha:0.6, beta:0.2, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.6, beta:0.3, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.6, beta:0.4, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.6, beta:0.5, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.6, beta:0.6, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.6, beta:0.7, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.6, beta:0.8, accuracy:0.3077, recall:0.4000, precision:0.1940 ,f1-score:0.2184\n",
      "alpha:0.6, beta:0.9, accuracy:0.4462, recall:0.5622, precision:0.4393 ,f1-score:0.4301\n",
      "alpha:0.6, beta:1.0, accuracy:0.5385, recall:0.6210, precision:0.4843 ,f1-score:0.5004\n",
      "alpha:0.7, beta:0.0, accuracy:0.3538, recall:0.3778, precision:0.2135 ,f1-score:0.2239\n",
      "alpha:0.7, beta:0.1, accuracy:0.2769, recall:0.3556, precision:0.1246 ,f1-score:0.1681\n",
      "alpha:0.7, beta:0.2, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.7, beta:0.3, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.7, beta:0.4, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.7, beta:0.5, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.7, beta:0.6, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.7, beta:0.7, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.7, beta:0.8, accuracy:0.3077, recall:0.4000, precision:0.1940 ,f1-score:0.2184\n",
      "alpha:0.7, beta:0.9, accuracy:0.4154, recall:0.5322, precision:0.4164 ,f1-score:0.3883\n",
      "alpha:0.7, beta:1.0, accuracy:0.4923, recall:0.5759, precision:0.4524 ,f1-score:0.4488\n",
      "alpha:0.8, beta:0.0, accuracy:0.3538, recall:0.3778, precision:0.2135 ,f1-score:0.2239\n",
      "alpha:0.8, beta:0.1, accuracy:0.2769, recall:0.3556, precision:0.1246 ,f1-score:0.1681\n",
      "alpha:0.8, beta:0.2, accuracy:0.2769, recall:0.3556, precision:0.1233 ,f1-score:0.1664\n",
      "alpha:0.8, beta:0.3, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.8, beta:0.4, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.8, beta:0.5, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.8, beta:0.6, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.8, beta:0.7, accuracy:0.2769, recall:0.3556, precision:0.1124 ,f1-score:0.1655\n",
      "alpha:0.8, beta:0.8, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.8, beta:0.9, accuracy:0.4000, recall:0.5189, precision:0.4139 ,f1-score:0.3672\n",
      "alpha:0.8, beta:1.0, accuracy:0.4923, recall:0.5759, precision:0.4496 ,f1-score:0.4452\n",
      "alpha:0.9, beta:0.0, accuracy:0.3385, recall:0.3556, precision:0.1786 ,f1-score:0.1953\n",
      "alpha:0.9, beta:0.1, accuracy:0.2769, recall:0.3556, precision:0.1233 ,f1-score:0.1664\n",
      "alpha:0.9, beta:0.2, accuracy:0.2769, recall:0.3556, precision:0.1233 ,f1-score:0.1664\n",
      "alpha:0.9, beta:0.3, accuracy:0.2769, recall:0.3556, precision:0.1233 ,f1-score:0.1664\n",
      "alpha:0.9, beta:0.4, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.9, beta:0.5, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.9, beta:0.6, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.9, beta:0.7, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:0.9, beta:0.8, accuracy:0.2923, recall:0.3778, precision:0.1252 ,f1-score:0.1828\n",
      "alpha:0.9, beta:0.9, accuracy:0.3385, recall:0.4622, precision:0.3250 ,f1-score:0.2964\n",
      "alpha:0.9, beta:1.0, accuracy:0.4923, recall:0.5759, precision:0.4496 ,f1-score:0.4452\n",
      "alpha:1.0, beta:0.0, accuracy:0.3385, recall:0.3556, precision:0.1786 ,f1-score:0.1953\n",
      "alpha:1.0, beta:0.1, accuracy:0.2615, recall:0.3333, precision:0.0885 ,f1-score:0.1379\n",
      "alpha:1.0, beta:0.2, accuracy:0.2769, recall:0.3556, precision:0.1233 ,f1-score:0.1664\n",
      "alpha:1.0, beta:0.3, accuracy:0.2769, recall:0.3556, precision:0.1233 ,f1-score:0.1664\n",
      "alpha:1.0, beta:0.4, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:1.0, beta:0.5, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:1.0, beta:0.6, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:1.0, beta:0.7, accuracy:0.2769, recall:0.3556, precision:0.1140 ,f1-score:0.1642\n",
      "alpha:1.0, beta:0.8, accuracy:0.2769, recall:0.3556, precision:0.1157 ,f1-score:0.1661\n",
      "alpha:1.0, beta:0.9, accuracy:0.3385, recall:0.4622, precision:0.3225 ,f1-score:0.2938\n",
      "alpha:1.0, beta:1.0, accuracy:0.4308, recall:0.5306, precision:0.4234 ,f1-score:0.3841\n"
     ]
    }
   ],
   "source": [
    "grid.fit(x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for testing in x_test:\n",
    "    pred.append(grid.best_estimator.predict(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363636363636364"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9444, Recall:0.9444, Precision:0.9524, F1-Score:0.9441\n",
      "\n",
      "\n",
      "\n",
      "             Predicted_1  Predicted_2  Predicted_3\n",
      "Predicted_1            6            0            0\n",
      "Predicted_2            1            5            0\n",
      "Predicted_3            0            0            6\n"
     ]
    }
   ],
   "source": [
    "test_evaluation(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "beb438d93d12d7d23f01da6e4ea2d18002922c4c96e890e3b42977e18c7fe317"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
