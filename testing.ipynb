{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "import copy\n",
    "import requests\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    # # check Z score\n",
    "    # zscore = pd.DataFrame()\n",
    "    # outlier = {}\n",
    "    # outlier_idx = []\n",
    "    # for col in data_scaled.columns:\n",
    "    #     if col != data_scaled.columns[0]:\n",
    "    #         zscore[f'{col}_z'] = sp.stats.zscore(data_scaled[col])\n",
    "    #         outlier[col] = zscore[f'{col}_z'][(zscore[f'{col}_z']>2.58) | (zscore[f'{col}_z']<-2.58)] # 99% = 2.58\n",
    "    #         outlier_idx.append(list(outlier[col].index))    \n",
    "    # outlier_idx_sum = sum(outlier_idx,[])\n",
    "    # data_scaled = data_scaled.drop(outlier_idx_sum)\n",
    "\n",
    "    # IQR outlier + mean으로 대체 \n",
    "    # class_label = data['Class Label']\n",
    "    label_list = np.unique(data['Class Label'].to_numpy())\n",
    "    processed_df = []\n",
    "    # data_pre = data.loc[:, data.columns != 'Class Label'].copy()\n",
    "    for class_num in label_list:\n",
    "        data_per_class = data.loc[data['Class Label'] == class_num, : ].copy()\n",
    "        data_pre = data_per_class.loc[:, data_per_class.columns != 'Class Label'].copy()\n",
    "        data_class = data_per_class.loc[:, data_per_class.columns == 'Class Label'].copy()\n",
    "        # data_pre = data.loc[:, data.columns != 'Class Label'].copy()\n",
    "            \n",
    "        for col in data_pre.columns:\n",
    "            q1 = np.quantile(data_pre[f'{col}'], 0.25)\n",
    "            q3 = np.quantile(data_pre[f'{col}'], 0.75)\n",
    "            IQR = q3 - q1\n",
    "            condition = (data_pre[f'{col}'] < (q1 - 1.5 * IQR)) | (data_pre[f'{col}'] > (q3 + 1.5 * IQR))\n",
    "            outlier = data_pre[condition]\n",
    "            data_pre[f'{col}'] = data_pre[f'{col}'].replace([data_pre[f'{col}'][outlier.index]], data_pre[f'{col}'].mean())\n",
    "\n",
    "        data_trimmed = pd.concat([data_class, data_pre], axis=1)\n",
    "\n",
    "        processed_df.append(data_trimmed)            \n",
    "    \n",
    "\n",
    "    data_pre = pd.concat(processed_df, axis=0)\n",
    "    \n",
    "    class_label = data_pre.loc[:, data_pre.columns == 'Class Label']\n",
    "    data_pre = data_pre.drop(['Class Label'], axis=1)\n",
    "    \n",
    "    # regularization 표준화\n",
    "    # regularization = StandardScaler()\n",
    "    # regularization.fit(data_pre)\n",
    "    # data_scaled = regularization.transform(data_pre)\n",
    "    # data_scaled = pd.DataFrame(data=data_scaled, columns=data_pre.columns)\n",
    "    # data_scaled[data_scaled.columns[0]] = label\n",
    "\n",
    "    sLink = 'https://github.com/2U1/ML_RDACOV/blob/master/scaler.pkl?raw=True'\n",
    "    sFile = BytesIO(requests.get(sLink).content)\n",
    "    scaler = pickle.load(sFile)\n",
    "    data_scaled = scaler.transform(data_pre)\n",
    "    data_scaled = pd.DataFrame(data=data_scaled, columns=data_pre.columns)\n",
    "\n",
    "    # # Normalization\n",
    "    # normalization = MinMaxScaler()\n",
    "    # normalization.fit(data_pre)\n",
    "    # data_nor = normalization.transform(data_pre)\n",
    "    # data_nor = pd.DataFrame(data=data_nor, columns=data_pre.columns)\n",
    "    # data_nor[data_nor.columns[0]] = data_pre[data_pre.columns[0]]\n",
    "    # data_nor[data_nor.columns[0]] = label\n",
    "    \n",
    "\n",
    "    data_processed = pd.concat([class_label, data_scaled], axis=1)\n",
    "\n",
    "    return data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred, average='macro')\n",
    "    precision = precision_score(y_test, pred, average='macro')\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "    print('Accuracy:{0:.4f}, Recall:{1:.4f}, Precision:{2:.4f}, F1-Score:{3:.4f}'.format(accuracy, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    confusion_df = pd.DataFrame(confusion,columns=['Predicted_1','Predicted_2', 'Predicted_3'],index=['Predicted_1','Predicted_2', 'Predicted_3'])\n",
    "    \n",
    "    return confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory, preprocess = False):\n",
    "    \n",
    "    global input_cnt, output_cnt, data, x, y\n",
    "\n",
    "    data = pd.read_csv(directory)\n",
    "    \n",
    "    if preprocess:\n",
    "        data = data_preprocessing(data)\n",
    "\n",
    "    input_cnt = data.loc[:, data.columns != 'Class Label'].shape[1]\n",
    "    # output_cnt = data['Class Label'].shape[1]\n",
    "    output_cnt = 1\n",
    "    y = data['Class Label'].to_numpy()\n",
    "    x = data.loc[:, data.columns != 'Class Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminentAnalysis():\n",
    "    def __init__(self, alpha=0.0, beta=0.0, eval_mode = False):\n",
    "        if not eval_mode:\n",
    "            self.learned = False\n",
    "            self.alpha = alpha\n",
    "            self.beta = beta\n",
    "            self.class_names = []\n",
    "            self.class_priors = {}\n",
    "            self.class_means = {}\n",
    "            self.regularized_covariances = {}\n",
    "            self.rda_covariances = {}\n",
    "            self.feature_dimension = 0\n",
    "            self.reset()\n",
    "\n",
    "        else:\n",
    "            self.load_parameter()\n",
    "\n",
    "\n",
    "    def load_parameter(self):\n",
    "        mLink = 'https://github.com/2U1/ML_RDACOV/blob/master/parameter.pkl?raw=true'\n",
    "        mfile = BytesIO(requests.get(mLink).content)\n",
    "        parameter = pickle.load(mfile)\n",
    "        \n",
    "\n",
    "        self.learned = True\n",
    "        self.alpha = parameter['alpha']\n",
    "        self.beta = parameter['beta']\n",
    "        self.class_names = parameter['class_name']\n",
    "        self.class_priors = parameter['class_priors']\n",
    "        self.class_means = parameter['class_means']\n",
    "        self.regularized_covariances = parameter['reg_cov']\n",
    "        self.rda_covariances = parameter['rda_cov']\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.learned = False\n",
    "        self.class_names = []\n",
    "        self.class_priors = {}\n",
    "        self.class_means = {}\n",
    "        self.regularized_covariances = {}\n",
    "        self.rda_covariances = {}\n",
    "\n",
    "\n",
    "    def return_parameters(self):\n",
    "        parameters = {\n",
    "            'alpha': self.alpha,\n",
    "            'beta': self.beta,\n",
    "            'class_name': self.class_names,\n",
    "            'class_priors': self.class_priors,\n",
    "            'class_means': self.class_means,\n",
    "            'reg_cov': self.regularized_covariances,\n",
    "            'rda_cov': self.rda_covariances\n",
    "        }\n",
    "\n",
    "        return parameters\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_names = np.unique(y)\n",
    "        class_covariances = {}\n",
    "        pooled_covariances = 0\n",
    "        self.feature_dimension = X.shape[1]\n",
    "        for i in self.class_names:\n",
    "            class_indices = np.where(y == i)[0]\n",
    "            class_samples = X[class_indices, :]\n",
    "            self.class_priors[i] = float(len(class_indices)) / len(y)\n",
    "            self.class_means[i] = np.mean(class_samples, axis=0)\n",
    "            class_covariances[i] = np.cov(class_samples, rowvar=0)\n",
    "            pooled_covariances += class_covariances[i] * self.class_priors[i]\n",
    "        # Calculate RDA regularized covariance matricies for each class\n",
    "        for i in self.class_names:\n",
    "            self.regularized_covariances[i] = (self.beta * pooled_covariances) + ((1 - self.beta) *class_covariances[i])\n",
    "            # self.regularized_covariances[i] = (self.beta * class_covariances[i]) + ((1 - self.beta) * pooled_covariances)\n",
    "\n",
    "        for i in self.class_names:\n",
    "            self.rda_covariances[i] = ((1-self.alpha) * self.regularized_covariances[i]) + (self.alpha * (1/self.feature_dimension) * np.trace(self.regularized_covariances[i]) * np.eye(self.regularized_covariances[i].shape[0]))\n",
    "        \n",
    "        self.learned = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        if not self.learned:\n",
    "            raise NameError('Fit model first')\n",
    "        # Determine probability of each class given input vector\n",
    "        \n",
    "        class_prob = {}\n",
    "        for i in self.class_names:\n",
    "            # Divid the class delta calculation into 3 parts\n",
    "            part1 = -0.5 * np.log1p(np.linalg.det(self.rda_covariances[i]))\n",
    "            # part2 = -0.5 * np.dot(np.dot((x - self.class_means[i]).T, np.linalg.pinv(self.rda_covariances[i])), (x - self.class_means[i]))\n",
    "            part2 = -0.5 * np.matmul(np.matmul((x - self.class_means[i]).T, np.linalg.pinv(self.rda_covariances[i])), (x - self.class_means[i]))\n",
    "            part3 = np.log(self.class_priors[i])\n",
    "            class_prob[i] = part1 + part2 + part3\n",
    "        return max(class_prob, key=class_prob.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchRDA():\n",
    "    def __init__(self, model, param_grid):\n",
    "        self.model = model\n",
    "        self.param_grid = param_grid\n",
    "        self.alpha = 0\n",
    "        self.beta = 0\n",
    "        self.best_covariance = {}\n",
    "        self.best_score = 0\n",
    "\n",
    "\n",
    "    def fit(self, X, y, cv=2):\n",
    "        \n",
    "        # metric_score = []\n",
    "\n",
    "        data_length = len(X)\n",
    "        \n",
    "        alpha_list = self.param_grid['alpha']\n",
    "        beta_list = self.param_grid['beta']\n",
    "        \n",
    "        if data_length % cv == 0:\n",
    "            cv_x = np.split(X, cv)\n",
    "            cv_y = np.split(y, cv)\n",
    "            \n",
    "        else:\n",
    "            remain = data_length % cv\n",
    "            cv_x = np.split(X[:-remain], cv)\n",
    "            cv_y = np.split(y[:-remain], cv)\n",
    "\n",
    "        for alpha in alpha_list:\n",
    "            for beta in beta_list:\n",
    "                accuracy_score_list = []\n",
    "                recall_score_list = []\n",
    "                precision_score_list = []\n",
    "                f1_score_list = []\n",
    "                for i in range(cv):\n",
    "                    self.model.reset()\n",
    "                    self.model.alpha = alpha\n",
    "                    self.model.beta = beta\n",
    "\n",
    "                    test_x_cv = cv_x[i]\n",
    "                    train_x_cv = np.vstack(cv_x[:i] + cv_x[i + 1:])\n",
    "\n",
    "                    test_y_cv = cv_y[i]\n",
    "                    train_y_cv = np.vstack(cv_y[:i] + cv_y[i + 1:]).flatten()\n",
    "\n",
    "                    \n",
    "                    self.model.fit(train_x_cv, train_y_cv)\n",
    "\n",
    "                    pred = []\n",
    "\n",
    "                    for data in test_x_cv:\n",
    "                        pred.append(self.model.predict(data))\n",
    "                    \n",
    "                    accuracy_score_list.append(accuracy_score(test_y_cv, pred))\n",
    "                    recall_score_list.append(recall_score(test_y_cv, pred, average='macro'))\n",
    "                    precision_score_list.append(precision_score(test_y_cv, pred, average='macro'))\n",
    "                    f1_score_list.append(f1_score(test_y_cv, pred, average='macro'))\n",
    "                \n",
    "                accuracy_mean_score = np.mean(np.array(accuracy_score_list))\n",
    "                recall_mean_score = np.mean(np.array(recall_score_list))\n",
    "                precision_mean_score = np.mean(np.array(precision_score_list))\n",
    "                f1_mean_score = np.mean(np.array(f1_score_list))\n",
    "\n",
    "                print(\"alpha:{0:.1f}, beta:{1:.1f}, accuracy:{2:.4f}, recall:{3:.4f}, precision:{4:.4f} ,f1-score:{5:.4f}\"\\\n",
    "                    .format(alpha, beta, accuracy_mean_score ,recall_mean_score ,precision_mean_score ,f1_mean_score))\n",
    "\n",
    "                if f1_mean_score > self.best_score:\n",
    "                    self.best_score = f1_mean_score\n",
    "                    self.alpha = alpha\n",
    "                    self.beta = beta\n",
    "                    self.best_covariance = copy.deepcopy(self.model.rda_covariances)\n",
    "                    self.best_estimator = copy.deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(test_x, test_y):\n",
    "\n",
    "    model = DiscriminentAnalysis(eval_mode=True)\n",
    "\n",
    "\n",
    "    prediction = []\n",
    "    \n",
    "    for testing in test_x:\n",
    "        prediction.append(model.predict(testing))\n",
    "\n",
    "\n",
    "    confusion = make_confusion(test_y, prediction)\n",
    "    \n",
    "    get_clf_eval(test_y, prediction)\n",
    "    print('\\n\\n')\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset('./facial_expression_train_dataset.csv', preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = DiscriminentAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': np.linspace(0.0, 1.0, num=11, endpoint=True),\n",
    "    'beta': np.linspace(0.0, 1.0, num=11, endpoint=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchRDA(dis, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:0.0, beta:0.0, accuracy:0.8769, recall:0.8511, precision:0.8930 ,f1-score:0.8527\n",
      "alpha:0.0, beta:0.1, accuracy:0.9385, recall:0.9422, precision:0.9422 ,f1-score:0.9302\n",
      "alpha:0.0, beta:0.2, accuracy:0.9692, recall:0.9644, precision:0.9756 ,f1-score:0.9658\n",
      "alpha:0.0, beta:0.3, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.0, beta:0.4, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.0, beta:0.5, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.0, beta:0.6, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.0, beta:0.7, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.0, beta:0.8, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.0, beta:0.9, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.0, beta:1.0, accuracy:0.9846, recall:0.9778, precision:0.9889 ,f1-score:0.9806\n",
      "alpha:0.1, beta:0.0, accuracy:0.9385, recall:0.9456, precision:0.9344 ,f1-score:0.9319\n",
      "alpha:0.1, beta:0.1, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.2, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.3, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.4, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.5, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.6, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.7, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.8, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.1, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.1, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.2, beta:0.0, accuracy:0.9692, recall:0.9733, precision:0.9700 ,f1-score:0.9683\n",
      "alpha:0.2, beta:0.1, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.2, beta:0.2, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.2, beta:0.3, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.2, beta:0.4, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.2, beta:0.5, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.2, beta:0.6, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.2, beta:0.7, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.2, beta:0.8, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.2, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.2, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.3, beta:0.0, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.3, beta:0.1, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.3, beta:0.2, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.3, beta:0.3, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.3, beta:0.4, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.3, beta:0.5, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.3, beta:0.6, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.3, beta:0.7, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.3, beta:0.8, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.3, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.3, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.4, beta:0.0, accuracy:0.9385, recall:0.9467, precision:0.9478 ,f1-score:0.9383\n",
      "alpha:0.4, beta:0.1, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.4, beta:0.2, accuracy:0.9692, recall:0.9733, precision:0.9700 ,f1-score:0.9683\n",
      "alpha:0.4, beta:0.3, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.4, beta:0.4, accuracy:0.9846, recall:0.9867, precision:0.9833 ,f1-score:0.9831\n",
      "alpha:0.4, beta:0.5, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.4, beta:0.6, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.4, beta:0.7, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.4, beta:0.8, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.4, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.4, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.5, beta:0.0, accuracy:0.9385, recall:0.9467, precision:0.9478 ,f1-score:0.9383\n",
      "alpha:0.5, beta:0.1, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.5, beta:0.2, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.5, beta:0.3, accuracy:0.9692, recall:0.9733, precision:0.9700 ,f1-score:0.9683\n",
      "alpha:0.5, beta:0.4, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.5, beta:0.5, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.5, beta:0.6, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.5, beta:0.7, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.5, beta:0.8, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.5, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.5, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.6, beta:0.0, accuracy:0.9385, recall:0.9467, precision:0.9478 ,f1-score:0.9383\n",
      "alpha:0.6, beta:0.1, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.6, beta:0.2, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.6, beta:0.3, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.6, beta:0.4, accuracy:0.9846, recall:0.9867, precision:0.9867 ,f1-score:0.9852\n",
      "alpha:0.6, beta:0.5, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.6, beta:0.6, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.6, beta:0.7, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.6, beta:0.8, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.6, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.6, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.7, beta:0.0, accuracy:0.9385, recall:0.9489, precision:0.9456 ,f1-score:0.9413\n",
      "alpha:0.7, beta:0.1, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.7, beta:0.2, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.7, beta:0.3, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.7, beta:0.4, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.7, beta:0.5, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.7, beta:0.6, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.7, beta:0.7, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.7, beta:0.8, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.7, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.7, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.8, beta:0.0, accuracy:0.9231, recall:0.9356, precision:0.9289 ,f1-score:0.9244\n",
      "alpha:0.8, beta:0.1, accuracy:0.9385, recall:0.9467, precision:0.9400 ,f1-score:0.9365\n",
      "alpha:0.8, beta:0.2, accuracy:0.9385, recall:0.9467, precision:0.9400 ,f1-score:0.9365\n",
      "alpha:0.8, beta:0.3, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.8, beta:0.4, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.8, beta:0.5, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.8, beta:0.6, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.8, beta:0.7, accuracy:0.9846, recall:0.9867, precision:0.9867 ,f1-score:0.9852\n",
      "alpha:0.8, beta:0.8, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.8, beta:0.9, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.8, beta:1.0, accuracy:1.0000, recall:1.0000, precision:1.0000 ,f1-score:1.0000\n",
      "alpha:0.9, beta:0.0, accuracy:0.9077, recall:0.9222, precision:0.9189 ,f1-score:0.9080\n",
      "alpha:0.9, beta:0.1, accuracy:0.9231, recall:0.9356, precision:0.9289 ,f1-score:0.9244\n",
      "alpha:0.9, beta:0.2, accuracy:0.9385, recall:0.9467, precision:0.9400 ,f1-score:0.9365\n",
      "alpha:0.9, beta:0.3, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.9, beta:0.4, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.9, beta:0.5, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:0.9, beta:0.6, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.9, beta:0.7, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:0.9, beta:0.8, accuracy:0.9846, recall:0.9867, precision:0.9867 ,f1-score:0.9852\n",
      "alpha:0.9, beta:0.9, accuracy:0.9846, recall:0.9867, precision:0.9867 ,f1-score:0.9852\n",
      "alpha:0.9, beta:1.0, accuracy:0.9846, recall:0.9867, precision:0.9867 ,f1-score:0.9852\n",
      "alpha:1.0, beta:0.0, accuracy:0.8615, recall:0.8822, precision:0.8986 ,f1-score:0.8550\n",
      "alpha:1.0, beta:0.1, accuracy:0.8769, recall:0.8956, precision:0.9033 ,f1-score:0.8753\n",
      "alpha:1.0, beta:0.2, accuracy:0.8769, recall:0.8956, precision:0.9033 ,f1-score:0.8753\n",
      "alpha:1.0, beta:0.3, accuracy:0.9231, recall:0.9333, precision:0.9300 ,f1-score:0.9201\n",
      "alpha:1.0, beta:0.4, accuracy:0.9385, recall:0.9467, precision:0.9400 ,f1-score:0.9365\n",
      "alpha:1.0, beta:0.5, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:1.0, beta:0.6, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:1.0, beta:0.7, accuracy:0.9538, recall:0.9600, precision:0.9567 ,f1-score:0.9534\n",
      "alpha:1.0, beta:0.8, accuracy:0.9692, recall:0.9733, precision:0.9733 ,f1-score:0.9704\n",
      "alpha:1.0, beta:0.9, accuracy:0.9846, recall:0.9867, precision:0.9867 ,f1-score:0.9852\n",
      "alpha:1.0, beta:1.0, accuracy:0.9846, recall:0.9867, precision:0.9867 ,f1-score:0.9852\n"
     ]
    }
   ],
   "source": [
    "grid.fit(x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = grid.best_estimator.return_parameters()\n",
    "with open('../Covariance/parameter.pkl','wb') as f:\n",
    "    pickle.dump(parameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for testing in x_test:\n",
    "    pred.append(grid.best_estimator.predict(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:1.0000, Recall:1.0000, Precision:1.0000, F1-Score:1.0000\n",
      "\n",
      "\n",
      "\n",
      "             Predicted_1  Predicted_2  Predicted_3\n",
      "Predicted_1            6            0            0\n",
      "Predicted_2            0            6            0\n",
      "Predicted_3            0            0            6\n"
     ]
    }
   ],
   "source": [
    "test_evaluation(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "beb438d93d12d7d23f01da6e4ea2d18002922c4c96e890e3b42977e18c7fe317"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
