{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "import copy\n",
    "import requests\n",
    "import pickle\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred, average='macro')\n",
    "    precision = precision_score(y_test, pred, average='macro')\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "    print('Accuracy:{0:.4f}, Recall:{1:.4f}, Precision:{2:.4f}, F1-Score:{3:.4f}'.format(accuracy, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    confusion_df = pd.DataFrame(confusion,columns=['Predicted_1','Predicted_2', 'Predicted_3'],index=['Predicted_1','Predicted_2', 'Predicted_3'])\n",
    "    \n",
    "    return confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "    \n",
    "    global input_cnt, output_cnt, data, x, y\n",
    "\n",
    "    data = pd.read_csv(directory)\n",
    "    input_cnt = data.loc[:, data.columns != 'Class Label'].shape[1]\n",
    "    # output_cnt = data['Class Label'].shape[1]\n",
    "    output_cnt = 1\n",
    "    y = data['Class Label'].to_numpy()\n",
    "    x = data.loc[:, data.columns != 'Class Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminentAnalysis():\n",
    "    def __init__(self, alpha=0.0, beta=0.0, eval_mode = False):\n",
    "        if not eval_mode:\n",
    "            self.learned = False\n",
    "            self.alpha = alpha\n",
    "            self.beta = beta\n",
    "            self.class_names = []\n",
    "            self.class_priors = {}\n",
    "            self.class_means = {}\n",
    "            self.regularized_covariances = {}\n",
    "            self.rda_covariances = {}\n",
    "            self.reset()\n",
    "\n",
    "        else:\n",
    "            self.load_parameter()\n",
    "\n",
    "\n",
    "    def load_parameter(self):\n",
    "        mLink = 'https://github.com/2U1/ML_RDACOV/blob/master/parameter.pkl?raw=true'\n",
    "        mfile = BytesIO(requests.get(mLink).content)\n",
    "        parameter = pickle.load(mfile)\n",
    "        \n",
    "\n",
    "        self.learned = True\n",
    "        self.alpha = parameter['alpha']\n",
    "        self.beta = parameter['beta']\n",
    "        self.class_names = parameter['class_name']\n",
    "        self.class_priors = parameter['calss_priors']\n",
    "        self.class_means = parameter['class_means']\n",
    "        self.regularized_covariances = parameter['reg_cov']\n",
    "        self.rda_covariances = parameter['rda_cov']\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.learned = False\n",
    "        self.class_names = []\n",
    "        self.class_priors = {}\n",
    "        self.class_means = {}\n",
    "        self.regularized_covariances = {}\n",
    "        self.rda_covariances = {}\n",
    "\n",
    "\n",
    "    def return_parameters(self):\n",
    "        parameters = {\n",
    "            'alpha': self.alpha,\n",
    "            'beta': self.beta,\n",
    "            'class_name': self.class_names,\n",
    "            'calss_priors': self.class_priors,\n",
    "            'class_means': self.class_means,\n",
    "            'reg_cov': self.regularized_covariances,\n",
    "            'rda_cov': self.rda_covariances\n",
    "        }\n",
    "\n",
    "        return parameters\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_names = np.unique(y)\n",
    "        class_covariances = {}\n",
    "        pooled_covariances = 0\n",
    "        for i in self.class_names:\n",
    "            class_indices = np.where(y == i)[0]\n",
    "            class_samples = X[class_indices, :]\n",
    "            self.class_priors[i] = float(len(class_indices)) / len(y)\n",
    "            self.class_means[i] = np.mean(class_samples, axis=0)\n",
    "            class_covariances[i] = np.cov(class_samples, rowvar=0)\n",
    "            pooled_covariances += class_covariances[i] * self.class_priors[i]\n",
    "        # Calculate RDA regularized covariance matricies for each class\n",
    "        for i in self.class_names:\n",
    "            self.regularized_covariances[i] = (self.beta * pooled_covariances) + ((1 - self.beta) *class_covariances[i])\n",
    "            # self.regularized_covariances[i] = (self.beta * class_covariances[i]) + ((1 - self.beta) * pooled_covariances)\n",
    "\n",
    "        for i in self.class_names:\n",
    "            self.rda_covariances[i] = ((1-self.alpha) * self.regularized_covariances[i]) + (self.alpha * (1/self.class_priors[i]) * np.trace(self.regularized_covariances[i]) * np.eye(self.regularized_covariances[i].shape[0]))\n",
    "        \n",
    "        self.learned = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        if not self.learned:\n",
    "            raise NameError('Fit model first')\n",
    "        # Determine probability of each class given input vector\n",
    "        \n",
    "        class_prob = {}\n",
    "        for i in self.class_names:\n",
    "            # Divid the class delta calculation into 3 parts\n",
    "            part1 = -0.5 * np.log1p(np.linalg.det(self.rda_covariances[i]))\n",
    "            # part2 = -0.5 * np.dot(np.dot((x - self.class_means[i]).T, np.linalg.pinv(self.rda_covariances[i])), (x - self.class_means[i]))\n",
    "            part2 = -0.5 * np.matmul(np.matmul((x - self.class_means[i]).T, np.linalg.pinv(self.rda_covariances[i])), (x - self.class_means[i]))\n",
    "            part3 = np.log(self.class_priors[i])\n",
    "            class_prob[i] = part1 + part2 + part3\n",
    "        return max(class_prob, key=class_prob.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchRDA():\n",
    "    def __init__(self, model, param_grid):\n",
    "        self.model = model\n",
    "        self.param_grid = param_grid\n",
    "        self.alpha = 0\n",
    "        self.beta = 0\n",
    "        self.best_covariance = {}\n",
    "        self.best_score = 0\n",
    "\n",
    "\n",
    "    def fit(self, X, y, cv=2):\n",
    "        \n",
    "        # metric_score = []\n",
    "\n",
    "        data_length = len(X)\n",
    "        \n",
    "        alpha_list = self.param_grid['alpha']\n",
    "        beta_list = self.param_grid['beta']\n",
    "        \n",
    "        if data_length % cv == 0:\n",
    "            cv_x = np.split(X, cv)\n",
    "            cv_y = np.split(y, cv)\n",
    "            \n",
    "        else:\n",
    "            remain = data_length % cv\n",
    "            cv_x = np.split(X[:-remain], cv)\n",
    "            cv_y = np.split(y[:-remain], cv)\n",
    "\n",
    "        for alpha in alpha_list:\n",
    "            for beta in beta_list:\n",
    "                accuracy_score_list = []\n",
    "                recall_score_list = []\n",
    "                precision_score_list = []\n",
    "                f1_score_list = []\n",
    "                for i in range(cv):\n",
    "                    self.model.reset()\n",
    "                    self.model.alpha = alpha\n",
    "                    self.model.beta = beta\n",
    "\n",
    "                    test_x_cv = cv_x[i]\n",
    "                    train_x_cv = np.vstack(cv_x[:i] + cv_x[i + 1:])\n",
    "\n",
    "                    test_y_cv = cv_y[i]\n",
    "                    train_y_cv = np.vstack(cv_y[:i] + cv_y[i + 1:]).flatten()\n",
    "\n",
    "                    \n",
    "                    self.model.fit(train_x_cv, train_y_cv)\n",
    "\n",
    "                    pred = []\n",
    "\n",
    "                    for data in test_x_cv:\n",
    "                        pred.append(self.model.predict(data))\n",
    "                    \n",
    "                    accuracy_score_list.append(accuracy_score(test_y_cv, pred))\n",
    "                    recall_score_list.append(recall_score(test_y_cv, pred, average='macro'))\n",
    "                    precision_score_list.append(precision_score(test_y_cv, pred, average='macro'))\n",
    "                    f1_score_list.append(f1_score(test_y_cv, pred, average='macro'))\n",
    "                \n",
    "                accuracy_mean_score = np.mean(np.array(accuracy_score_list))\n",
    "                recall_mean_score = np.mean(np.array(recall_score_list))\n",
    "                precision_mean_score = np.mean(np.array(precision_score_list))\n",
    "                f1_mean_score = np.mean(np.array(f1_score_list))\n",
    "\n",
    "                print(\"alpha:{0:.1f}, beta:{1:.1f}, accuracy:{2:.4f}, recall:{3:.4f}, precision:{4:.4f} ,f1-score:{5:.4f}\"\\\n",
    "                    .format(alpha, beta, accuracy_mean_score ,recall_mean_score ,precision_mean_score ,f1_mean_score))\n",
    "\n",
    "                if f1_mean_score > self.best_score:\n",
    "                    self.best_score = f1_mean_score\n",
    "                    self.alpha = alpha\n",
    "                    self.beta = beta\n",
    "                    self.best_covariance = copy.deepcopy(self.model.rda_covariances)\n",
    "                    self.best_estimator = copy.deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(test_x, test_y):\n",
    "\n",
    "    model = DiscriminentAnalysis(eval_mode=True)\n",
    "\n",
    "\n",
    "    prediction = []\n",
    "    \n",
    "    for testing in test_x:\n",
    "        prediction.append(model.predict(testing))\n",
    "\n",
    "\n",
    "    confusion = make_confusion(test_y, prediction)\n",
    "    \n",
    "    get_clf_eval(test_y, prediction)\n",
    "    print('\\n\\n')\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "beb438d93d12d7d23f01da6e4ea2d18002922c4c96e890e3b42977e18c7fe317"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
